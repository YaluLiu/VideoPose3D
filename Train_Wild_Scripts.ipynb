{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import sys\n",
    "import errno\n",
    "\n",
    "from common.camera import *\n",
    "from common.visualization import *\n",
    "from common.utils import *\n",
    "from common.generators import ChunkedGenerator, UnchunkedGenerator\n",
    "from common.h36m_dataset import Human36mDataset, preprocess_Human36m\n",
    "from common.visualization import *\n",
    "from common.model import *\n",
    "from common.xianhui_dataset import *\n",
    "import matplotlib\n",
    "import glob\n",
    "import plotly\n",
    "import json\n",
    "%matplotlib inline\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "from scripts.build_model import *\n",
    "from scripts.train import *\n",
    "from scripts.eval import *\n",
    "from scripts.data_preprocessing_cmu_mocap import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_path = \"../wild_data_cmu/output_human/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " load 3d data \n",
      " processing 3d data \n",
      " load 2d keypoints \n",
      " processing 2d keypoints \n"
     ]
    }
   ],
   "source": [
    "dataset, keypoints = load_and_preprocess_cmu_mocap(data_root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = sorted(dataset.subjects())\n",
    "subjects_train = subjects[:23]\n",
    "subjects_semi = subjects[:23]\n",
    "subjects_test = subjects[23:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras_valid, poses_valid, poses_valid_2d = fetch(dataset = dataset,\n",
    "                                                   keypoints = keypoints, \n",
    "                                                   subjects = subjects_test, \n",
    "                                                   stride = 1)\n",
    "\n",
    "cameras_train, poses_train, poses_train_2d = fetch(dataset = dataset,\n",
    "                                                   keypoints = keypoints, \n",
    "                                                   subjects = subjects_train, \n",
    "                                                   stride = 1)\n",
    "\n",
    "cameras_semi, _, poses_semi_2d = fetch(dataset = dataset,\n",
    "                                       keypoints = keypoints,\n",
    "                                       subjects = subjects_semi,\n",
    "                                       stride = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint checkpoints/cmu_epoch_50.bin\n",
      "This model was trained for 50 epochs\n"
     ]
    }
   ],
   "source": [
    "resume = True\n",
    "filter_widths = [3,3,3,3,3]\n",
    "model_pos_train, model_pos, model_traj, model_traj_train = build_models(17, 2, 17, filter_widths)\n",
    "\n",
    "if resume:\n",
    "    chk_filename = \"checkpoints/cmu_epoch_50.bin\"\n",
    "    print('Loading checkpoint', chk_filename)\n",
    "    checkpoint = torch.load(chk_filename, map_location=lambda storage, loc: storage)\n",
    "    print('This model was trained for {} epochs'.format(checkpoint['epoch']))\n",
    "    model_pos_train.load_state_dict(checkpoint['model_pos'])\n",
    "    model_pos.load_state_dict(checkpoint['model_pos'])\n",
    "    model_traj_train.load_state_dict(checkpoint['model_traj'])\n",
    "    model_traj.load_state_dict(checkpoint['model_traj'])\n",
    "    \n",
    "\n",
    "# load model on gpu\n",
    "if torch.cuda.is_available():\n",
    "    model_pos = model_pos.cuda()\n",
    "    model_pos_train = model_pos_train.cuda()\n",
    "    model_traj = model_traj.cuda()\n",
    "    model_traj_train = model_traj_train.cuda()\n",
    "\n",
    "# copy on multi-gpu\n",
    "devices = [0, 1,2,3]\n",
    "model_pos_train = nn.DataParallel(model_pos_train, device_ids=devices)\n",
    "model_traj_train = nn.DataParallel(model_traj_train, device_ids=devices)\n",
    "\n",
    "models = {}\n",
    "models[\"model_pos_train\"] = model_pos_train\n",
    "models[\"model_pos\"] = model_pos\n",
    "models[\"model_traj_train\"] = model_traj_train\n",
    "models[\"model_traj\"] = model_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive_field = model_pos.receptive_field()\n",
    "pad = (receptive_field - 1) // 2\n",
    "batch_size = 4096 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = UnchunkedGenerator(cameras_valid, poses_valid, poses_valid_2d, pad=pad, causal_shift=0, augment=False)\n",
    "train_generator = ChunkedGenerator(batch_size, cameras_train, poses_train, poses_train_2d, 1, pad=pad, causal_shift=0, shuffle=True, augment=False)\n",
    "train_generator_eval = UnchunkedGenerator(cameras_train, poses_train, poses_train_2d, pad=pad, causal_shift=0, augment=False)\n",
    "semi_generator = ChunkedGenerator(batch_size, cameras_semi, None, poses_semi_2d, 1, pad=pad, causal_shift=0, shuffle=True, random_seed=4321, augment=False, endless=True)\n",
    "semi_generator_eval = UnchunkedGenerator(cameras_semi, None, poses_semi_2d, pad=pad, causal_shift=0, augment=False)\n",
    "\n",
    "# if resume:\n",
    "#     train_generator.set_random_state(checkpoint['random_state'])\n",
    "#     semi_generator.set_random_state(checkpoint['random_state_semi'])\n",
    "\n",
    "generators = {}\n",
    "generators[\"test_generator\"] = test_generator\n",
    "generators[\"train_generator\"] = train_generator\n",
    "generators[\"train_generator_eval\"] = train_generator_eval\n",
    "generators[\"semi_generator\"] = semi_generator\n",
    "generators[\"semi_generator_eval\"] = semi_generator_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "initial_momentum = 0.1\n",
    "final_momentum = 0.001\n",
    "lr_decay = 0.99\n",
    "optimizer = optim.Adam(list(model_pos_train.parameters()) + list(model_traj_train.parameters()),\n",
    "                               lr=lr, amsgrad=True)\n",
    "# if resume:\n",
    "#     optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "#     lr = checkpoint[\"lr\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = Losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_folder = \"checkpoints/\"\n",
    "save_freq = 10 \n",
    "warmup = 0\n",
    "epochs = 100\n",
    "\n",
    "if resume:\n",
    "    start_epoch = checkpoint['epoch']\n",
    "else:\n",
    "    start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = []\n",
    "momentums = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - epoch  50 train : 100%|██████████| 451/451 [14:58<00:00,  1.88s/it]\n",
      " evaluate on test set : 100%|██████████| 402/402 [00:13<00:00, 30.86it/s]\n",
      " evaluate on train set : 100%|██████████| 1956/1956 [00:30<00:00, 63.80it/s] \n",
      " evaluate on unlabel train set : 100%|██████████| 1956/1956 [00:28<00:00, 67.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_valid :  0.387113200424957\n",
      "traj_train_eval :  0.23986167234302702\n",
      "Saving checkpoint to checkpoints/cmu_epoch_50.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - epoch  51 train :  98%|█████████▊| 440/451 [14:27<00:21,  1.95s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs+1):\n",
    "    if epoch < warmup:\n",
    "        skip = True\n",
    "    else:\n",
    "        skip = False\n",
    "        \n",
    "    models, optimizer, train_losses = train(models, generators, optimizer, pad, skip, False, True, epoch, cmu = True)    \n",
    "    eval_losses = evaluate(models, generators, pad, cmu = True)\n",
    "    losses.update(train_losses, eval_losses)    \n",
    "    print(\"traj_valid : \", losses.losses_traj_valid[-1])\n",
    "    print(\"traj_train_eval : \", losses.losses_traj_train_eval[-1])\n",
    "    \n",
    "    # Decay learning rate exponentially\n",
    "    lr *= lr_decay\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] *= lr_decay\n",
    "\n",
    "    # Decay BatchNorm momentum\n",
    "    momentum = initial_momentum * np.exp(-epoch/epochs * np.log(initial_momentum/final_momentum))\n",
    "    models[\"model_pos_train\"].module.expand_bn.momentum = momentum\n",
    "    models[\"model_traj_train\"].module.expand_bn.momentum = momentum\n",
    "    # print(\" -- epoch {:3d} -- \".format(i))\n",
    "    \n",
    "    lrs.append(lr)\n",
    "    momentums.append(momentum)\n",
    "    \n",
    "    if epoch % save_freq == 0:\n",
    "        chk_path = os.path.join(checkpoint_folder, 'cmu_epoch_{}.bin'.format(epoch))\n",
    "        print('Saving checkpoint to', chk_path)\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'lr': lr,\n",
    "                'random_state': generators[\"train_generator\"].random_state(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'model_pos': states_convert(models[\"model_pos_train\"]),\n",
    "                'model_traj': states_convert(models[\"model_traj_train\"]),\n",
    "                'random_state_semi': generators[\"semi_generator\"].random_state(),\n",
    "            }, chk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = losses.visualize(start_epoch, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
